-- Migration: Add output validation tracking for Phase 6.1
-- Date: 2026-02-16
-- Related: AAA_AI_WORKER_OUTPUT_VALIDATION_COMPLETE_PLAN.md Section 2.3

-- ==========================================
-- TABLE 1: output_validations
-- ==========================================
-- Stores validation results for all AI worker generated code
CREATE TABLE IF NOT EXISTS output_validations (
    validation_id SERIAL PRIMARY KEY,

    -- Worker identification
    worker_id VARCHAR(255) NOT NULL,
    task_name VARCHAR(255),

    -- Generated files
    generated_files JSONB NOT NULL,  -- Array of file paths: ["path/to/file1.py", "path/to/file2.py"]

    -- Decision & scoring
    decision VARCHAR(50) NOT NULL CHECK (decision IN ('APPROVE', 'REJECT', 'MANUAL_REVIEW')),
    overall_score INTEGER CHECK (overall_score >= 0 AND overall_score <= 100),

    -- Individual validator results (stored as JSONB for flexibility)
    syntax_result JSONB,  -- {valid: bool, errors: [...], line_numbers: [...]}
    security_result JSONB,  -- {severity: "CRITICAL/HIGH/MEDIUM/LOW", findings: [...], safe: bool}
    dependency_result JSONB,  -- {all_available: bool, missing: [...], available: [...], unknown: [...]}
    test_result JSONB,  -- {passed: int, failed: int, errors: [...], duration: float}
    quality_result JSONB,  -- {score: int, complexity: int, issues: [...], recommendations: [...]}

    -- Critical issues & recommendations
    blocking_issues JSONB,  -- Array of critical issues preventing deployment: ["Syntax errors", "CRITICAL security finding"]
    recommendation TEXT,  -- Human-readable recommendation: "Fix 2 syntax errors before deployment"

    -- Audit metadata
    created_at TIMESTAMP DEFAULT NOW(),
    validated_by VARCHAR(255) DEFAULT 'output_validator',  -- System component that ran validation

    -- Foreign key to approval_requests (if manual review created)
    approval_id INTEGER  -- References approval_requests(id) - added below after table exists
);

-- Indexes for output_validations
CREATE INDEX IF NOT EXISTS idx_output_validations_worker ON output_validations(worker_id);
CREATE INDEX IF NOT EXISTS idx_output_validations_decision ON output_validations(decision);
CREATE INDEX IF NOT EXISTS idx_output_validations_created ON output_validations(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_output_validations_approval ON output_validations(approval_id) WHERE approval_id IS NOT NULL;

-- Comments for output_validations
COMMENT ON TABLE output_validations IS 'Validation results for AI worker generated code (Phase 6.1 Output Validation Pipeline)';
COMMENT ON COLUMN output_validations.worker_id IS 'AI worker identifier that generated the code';
COMMENT ON COLUMN output_validations.task_name IS 'Human-readable task name (e.g., "Semantic Analyzer Implementation")';
COMMENT ON COLUMN output_validations.generated_files IS 'JSONB array of file paths generated by worker';
COMMENT ON COLUMN output_validations.decision IS 'Final validation decision: APPROVE (auto-deploy), REJECT (block), MANUAL_REVIEW (human needed)';
COMMENT ON COLUMN output_validations.overall_score IS 'Composite quality score 0-100 (70+ = APPROVE, <30 = REJECT, 30-70 = MANUAL_REVIEW)';
COMMENT ON COLUMN output_validations.syntax_result IS 'Syntax validation results (parse errors, line numbers)';
COMMENT ON COLUMN output_validations.security_result IS 'Security scan results (secrets, dangerous patterns, vulnerabilities)';
COMMENT ON COLUMN output_validations.dependency_result IS 'Dependency verification results (missing imports, availability)';
COMMENT ON COLUMN output_validations.test_result IS 'Test execution results (pytest/unittest pass/fail counts)';
COMMENT ON COLUMN output_validations.quality_result IS 'Code quality scoring (complexity, documentation, best practices)';
COMMENT ON COLUMN output_validations.blocking_issues IS 'JSONB array of critical issues that triggered REJECT decision';
COMMENT ON COLUMN output_validations.recommendation IS 'Actionable recommendation for worker (e.g., "Install missing dependency: pip install nltk")';
COMMENT ON COLUMN output_validations.approval_id IS 'Foreign key to approval_requests if MANUAL_REVIEW decision created approval';

-- ==========================================
-- TABLE 2: worker_validation_history
-- ==========================================
-- Tracks validation success/failure patterns per worker (for Watcher integration)
CREATE TABLE IF NOT EXISTS worker_validation_history (
    history_id SERIAL PRIMARY KEY,

    -- Worker identification
    worker_id VARCHAR(255) NOT NULL UNIQUE,  -- One row per worker

    -- Success/failure counters
    success_count INTEGER DEFAULT 0 CHECK (success_count >= 0),
    failure_count INTEGER DEFAULT 0 CHECK (failure_count >= 0),

    -- Timestamps
    last_success_at TIMESTAMP,
    last_failure_at TIMESTAMP,
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Indexes for worker_validation_history
CREATE INDEX IF NOT EXISTS idx_worker_history_failure_rate ON worker_validation_history(failure_count DESC, success_count);
CREATE INDEX IF NOT EXISTS idx_worker_history_recent_failure ON worker_validation_history(last_failure_at DESC) WHERE last_failure_at IS NOT NULL;

-- Comments for worker_validation_history
COMMENT ON TABLE worker_validation_history IS 'Aggregated validation success/failure history per worker (used by Watcher for pattern detection)';
COMMENT ON COLUMN worker_validation_history.worker_id IS 'AI worker identifier (unique - one row per worker)';
COMMENT ON COLUMN worker_validation_history.success_count IS 'Total count of APPROVE decisions for this worker';
COMMENT ON COLUMN worker_validation_history.failure_count IS 'Total count of REJECT decisions for this worker';
COMMENT ON COLUMN worker_validation_history.last_success_at IS 'Timestamp of most recent APPROVE decision';
COMMENT ON COLUMN worker_validation_history.last_failure_at IS 'Timestamp of most recent REJECT decision';
COMMENT ON COLUMN worker_validation_history.updated_at IS 'Timestamp of last update (any validation)';

-- ==========================================
-- ALTER TABLE: approval_requests
-- ==========================================
-- Add bidirectional link between approvals and output validations
-- Note: approval_requests table exists in SQLite (approval_store.py) and may not exist in Postgres
-- This migration is defensive - only adds column if table exists

DO $$
BEGIN
    -- Check if approval_requests table exists (Postgres deployment)
    IF EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'approval_requests') THEN
        -- Add output_validation_id column if it doesn't exist
        IF NOT EXISTS (
            SELECT FROM pg_attribute
            WHERE attrelid = 'approval_requests'::regclass
            AND attname = 'output_validation_id'
        ) THEN
            ALTER TABLE approval_requests
            ADD COLUMN output_validation_id INTEGER REFERENCES output_validations(validation_id);

            CREATE INDEX IF NOT EXISTS idx_approval_requests_output_validation
            ON approval_requests(output_validation_id) WHERE output_validation_id IS NOT NULL;

            COMMENT ON COLUMN approval_requests.output_validation_id IS
            'Foreign key to output_validations (if approval was triggered by validation failure)';
        END IF;
    END IF;
END $$;

-- ==========================================
-- HELPER FUNCTIONS (OPTIONAL)
-- ==========================================
-- Function to update worker validation history after each validation
CREATE OR REPLACE FUNCTION update_worker_validation_history()
RETURNS TRIGGER AS $$
BEGIN
    -- Insert or update worker validation history
    INSERT INTO worker_validation_history (
        worker_id,
        success_count,
        failure_count,
        last_success_at,
        last_failure_at,
        updated_at
    ) VALUES (
        NEW.worker_id,
        CASE WHEN NEW.decision = 'APPROVE' THEN 1 ELSE 0 END,
        CASE WHEN NEW.decision = 'REJECT' THEN 1 ELSE 0 END,
        CASE WHEN NEW.decision = 'APPROVE' THEN NEW.created_at ELSE NULL END,
        CASE WHEN NEW.decision = 'REJECT' THEN NEW.created_at ELSE NULL END,
        NEW.created_at
    )
    ON CONFLICT (worker_id) DO UPDATE SET
        success_count = worker_validation_history.success_count + CASE WHEN NEW.decision = 'APPROVE' THEN 1 ELSE 0 END,
        failure_count = worker_validation_history.failure_count + CASE WHEN NEW.decision = 'REJECT' THEN 1 ELSE 0 END,
        last_success_at = CASE
            WHEN NEW.decision = 'APPROVE' THEN NEW.created_at
            ELSE worker_validation_history.last_success_at
        END,
        last_failure_at = CASE
            WHEN NEW.decision = 'REJECT' THEN NEW.created_at
            ELSE worker_validation_history.last_failure_at
        END,
        updated_at = NEW.created_at;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Trigger to automatically update history on each validation insert
DROP TRIGGER IF EXISTS trigger_update_validation_history ON output_validations;
CREATE TRIGGER trigger_update_validation_history
    AFTER INSERT ON output_validations
    FOR EACH ROW
    EXECUTE FUNCTION update_worker_validation_history();

COMMENT ON FUNCTION update_worker_validation_history() IS
'Automatically updates worker_validation_history counters when new validation is inserted';

-- ==========================================
-- VERIFICATION QUERIES (for testing)
-- ==========================================
-- These are example queries for operators to verify migration success
-- Run after migration completes

-- 1. Verify tables exist
-- SELECT tablename FROM pg_tables WHERE schemaname = 'public' AND tablename IN ('output_validations', 'worker_validation_history');

-- 2. Verify indexes exist
-- SELECT indexname FROM pg_indexes WHERE schemaname = 'public' AND tablename = 'output_validations';

-- 3. Test insert (remove after testing)
-- INSERT INTO output_validations (worker_id, task_name, generated_files, decision, overall_score)
-- VALUES ('TEST_WORKER_001', 'Test Migration', '["test.py"]'::jsonb, 'APPROVE', 85);

-- 4. Verify trigger works (check worker_validation_history after insert)
-- SELECT * FROM worker_validation_history WHERE worker_id = 'TEST_WORKER_001';

-- 5. Cleanup test data
-- DELETE FROM output_validations WHERE worker_id = 'TEST_WORKER_001';
-- DELETE FROM worker_validation_history WHERE worker_id = 'TEST_WORKER_001';

-- ==========================================
-- MIGRATION COMPLETE
-- ==========================================
-- Phase 6.1 Output Validation database schema deployed
-- Next steps:
-- 1. Verify migration with test queries above
-- 2. Deploy output validation pipeline code (Python validators)
-- 3. Test /output_validation/validate API endpoint
-- 4. Monitor validation_results for 48 hours in TEST
-- 5. Deploy to PRD after validation
