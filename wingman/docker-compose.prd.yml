name: wingman-prd

# Production environment configuration
# Environment: PRD
# Purpose: Production Wingman deployment
# Generated: 2025-12-16

services:
  # Wingman API Service - Production
  wingman-api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: wingman-prd-api
    environment:
      - FLASK_ENV=${FLASK_ENV:-production}
      # PRD uses 5001 to avoid macOS AirPlay Receiver conflict on port 5000
      - API_PORT=${API_PORT:-5001}
      - DB_HOST=${DB_HOST:-postgres}
      - DB_PORT=${DB_PORT:-5432}
      - DB_NAME=${DB_NAME:-wingman_prd}
      - DB_USER=${DB_USER:-wingman_prd}
      - DB_PASSWORD=${DB_PASSWORD:?DB_PASSWORD is required}
      - TIMESCALE_HOST=${TIMESCALE_HOST:-postgres}
      - TIMESCALE_PORT=${TIMESCALE_PORT:-5432}
      - TIMESCALE_DB=${DB_NAME:-wingman_prd}
      - TIMESCALE_USER=${DB_USER:-wingman_prd}
      - TIMESCALE_PASS=${DB_PASSWORD:?DB_PASSWORD is required}
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - OLLAMA_HOST=${OLLAMA_HOST:-host.docker.internal}
      - OLLAMA_PORT=${OLLAMA_PORT:-11434}
      # mem0 Configuration (loaded from .env.prd)
      - MEM0_API_URL=${MEM0_API_URL:-http://127.0.0.1:8889}
      - MEM0_USER_ID=${MEM0_USER_ID:-wingman_system}
      # OpenAI API Key (for AI workers - loaded from .env.prd)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - DEPLOYMENT_ENV=prd
      - WINGMAN_APPROVAL_DB=${WINGMAN_APPROVAL_DB:-data/approvals.db}
      # Phase 4 (HITL) auth: prefer role-separated keys; legacy key still supported.
      - WINGMAN_APPROVAL_READ_KEYS=${WINGMAN_APPROVAL_READ_KEYS:-}
      - WINGMAN_APPROVAL_DECIDE_KEYS=${WINGMAN_APPROVAL_DECIDE_KEYS:-}
      - WINGMAN_APPROVAL_REQUEST_KEYS=${WINGMAN_APPROVAL_REQUEST_KEYS:-}
      - WINGMAN_APPROVAL_API_KEY=${WINGMAN_APPROVAL_API_KEY:-}
      # Phase 5 (Execution Gateway) JWT secret for capability tokens
      - GATEWAY_JWT_SECRET=${GATEWAY_JWT_SECRET:?GATEWAY_JWT_SECRET is required}
    ports:
      - "127.0.0.1:${API_PORT:-5001}:8001"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - wingman-network-prd
    volumes:
      - ./logs/prd:/app/logs
      - ./data/prd:/app/data
    restart: unless-stopped
    labels:
      - "com.wingman.compose-file=docker-compose.prd.yml"
      - "com.wingman.environment=production"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # Wingman Watcher - Phase 4: Autonomous Monitoring
  wingman-watcher:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: wingman-prd-watcher
    command: ["python", "-u", "wingman_watcher.py"]
    environment:
      - WINGMAN_AUDIT_LOG=${WINGMAN_AUDIT_LOG:-data/claims_audit.jsonl}
      - WINGMAN_WATCHER_STATE=${WINGMAN_WATCHER_STATE:-data/watcher_state.json}
      - WINGMAN_WATCHER_INCIDENTS=${WINGMAN_WATCHER_INCIDENTS:-data/incidents.jsonl}
      - WINGMAN_WATCHER_INTERVAL_SEC=${WINGMAN_WATCHER_INTERVAL_SEC:-2.0}
      - WINGMAN_WATCHER_DEDUP_SEC=${WINGMAN_WATCHER_DEDUP_SEC:-600}
      - WINGMAN_NOTIFY_BACKENDS=${WINGMAN_NOTIFY_BACKENDS:-stdout,telegram}
      - WINGMAN_WEBHOOK_URL=${WINGMAN_WEBHOOK_URL:-}
      - TELEGRAM_BOT_TOKEN=${BOT_TOKEN:?BOT_TOKEN is required}
      - TELEGRAM_CHAT_ID=${CHAT_ID:?CHAT_ID is required}
      - WINGMAN_REMEDIATE_MODE=${WINGMAN_REMEDIATE_MODE:-disabled}
      - WINGMAN_REMEDIATE_CMD=${WINGMAN_REMEDIATE_CMD:-}
      - DEPLOYMENT_ENV=prd
      # Approval monitoring configuration
      - WINGMAN_API_URL=http://wingman-api:8001
      - WINGMAN_APPROVAL_READ_KEY=${WINGMAN_APPROVAL_READ_KEY:-}
      - WINGMAN_APPROVAL_NOTIFY_ENABLED=${WINGMAN_APPROVAL_NOTIFY_ENABLED:-true}
      - WINGMAN_APPROVAL_CHECK_INTERVAL_SEC=${WINGMAN_APPROVAL_CHECK_INTERVAL_SEC:-30}
    depends_on:
      - wingman-api
    networks:
      - wingman-network-prd
    volumes:
      - ./logs/prd:/app/logs
      - ./data/prd:/app/data
    restart: unless-stopped
    # Watcher is not an HTTP server; disable the inherited Dockerfile healthcheck.
    healthcheck:
      disable: true
    labels:
      - "com.wingman.compose-file=docker-compose.prd.yml"
      - "com.wingman.environment=production"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Telegram Bot Service - Production
  telegram-bot:
    build:
      context: .
      dockerfile: Dockerfile.bot
    container_name: wingman-prd-telegram
    environment:
      - BOT_TOKEN=${BOT_TOKEN:?BOT_TOKEN is required}
      - CHAT_ID=${CHAT_ID:?CHAT_ID is required}
      # Use container_name hostname to avoid Docker DNS alias quirks in PRD.
      - API_URL=${API_URL:-http://wingman-prd-api:8001}
      # Bot should only receive minimal keys required to read and decide.
      - WINGMAN_APPROVAL_READ_KEY=${WINGMAN_APPROVAL_READ_KEY:-}
      - WINGMAN_APPROVAL_DECIDE_KEY=${WINGMAN_APPROVAL_DECIDE_KEY:-}
      - WINGMAN_APPROVAL_API_KEY=${WINGMAN_APPROVAL_API_KEY:-}
      - DB_HOST=${DB_HOST:-postgres}
      - DB_PORT=${DB_PORT:-5432}
      - DB_NAME=${DB_NAME:-wingman_prd}
      - DB_USER=${DB_USER:-wingman_prd}
      - DB_PASSWORD=${DB_PASSWORD:?DB_PASSWORD is required}
      - TIMESCALE_HOST=${TIMESCALE_HOST:-postgres}
      - TIMESCALE_PORT=${TIMESCALE_PORT:-5432}
      - TIMESCALE_DB=${DB_NAME:-wingman_prd}
      - TIMESCALE_USER=${DB_USER:-wingman_prd}
      - TIMESCALE_PASS=${DB_PASSWORD:?DB_PASSWORD is required}
      - DEPLOYMENT_ENV=prd
    depends_on:
      - wingman-api
      - postgres
    networks:
      - wingman-network-prd
    volumes:
      - ./logs/prd:/app/logs
    restart: unless-stopped
    labels:
      - "com.wingman.compose-file=docker-compose.prd.yml"
      - "com.wingman.environment=production"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
  # Execution Gateway - Phase 5: Capability-Based Execution
  execution-gateway:
    build:
      context: .
      dockerfile: Dockerfile.gateway
    container_name: wingman-prd-gateway
    environment:
      - GATEWAY_JWT_SECRET=${GATEWAY_JWT_SECRET:?GATEWAY_JWT_SECRET is required}
      - GATEWAY_PORT=5002
      - AUDIT_STORAGE=postgres
      - ALLOWED_ENVIRONMENTS=prd
      # Database connection for audit logs
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${DB_NAME:-wingman_prd}
      - POSTGRES_USER=${DB_USER:-wingman_prd}
      - POSTGRES_PASSWORD=${DB_PASSWORD:?DB_PASSWORD is required}
      - DEPLOYMENT_ENV=prd
    ports:
      - "127.0.0.1:5002:5002"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - wingman-network-prd
    volumes:
      - ./logs/prd:/app/logs
      - ./data/prd:/app/data
      - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped
    labels:
      - "com.wingman.compose-file=docker-compose.prd.yml"
      - "com.wingman.environment=production"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5002/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  # PostgreSQL with TimescaleDB - Production
  postgres:
    image: timescale/timescaledb:latest-pg15
    container_name: wingman-prd-postgres
    environment:
      - POSTGRES_USER=${DB_USER:-wingman_prd}
      - POSTGRES_PASSWORD=${DB_PASSWORD:?DB_PASSWORD is required}
      - POSTGRES_DB=${DB_NAME:-wingman_prd}
      - POSTGRES_HOST_AUTH_METHOD=${POSTGRES_HOST_AUTH_METHOD:-md5}
      - DEPLOYMENT_ENV=prd
    # Do NOT reuse DB_PORT for host publishing; DB_PORT is the *internal* port (usually 5432).
    # Use DB_HOST_PORT to avoid collisions with local Postgres/OrbStack.
    ports:
      - "127.0.0.1:${DB_HOST_PORT:-5434}:5432"
    volumes:
      - postgres_data_prd:/var/lib/postgresql/data
      - ./database_schema.sql:/docker-entrypoint-initdb.d/01-schema.sql:ro
    networks:
      - wingman-network-prd
    restart: unless-stopped
    labels:
      - "com.wingman.compose-file=docker-compose.prd.yml"
      - "com.wingman.environment=production"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-wingman_prd} -d ${DB_NAME:-wingman_prd}"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis Cache - Production
  redis:
    image: redis:7-alpine
    container_name: wingman-prd-redis
    # Do NOT reuse REDIS_PORT for host publishing; REDIS_PORT is the *internal* port (usually 6379).
    # Use REDIS_HOST_PORT to avoid collisions with local Redis.
    ports:
      - "127.0.0.1:${REDIS_HOST_PORT:-6380}:6379"
    volumes:
      - redis_data_prd:/data
    networks:
      - wingman-network-prd
    restart: unless-stopped
    labels:
      - "com.wingman.compose-file=docker-compose.prd.yml"
      - "com.wingman.environment=production"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Ollama for Mistral 7B - Production
  # Note: Using host Ollama instance to avoid port conflicts
  # If host Ollama is not available, uncomment the ollama service below
  # and use a different port (e.g., 11435)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: wingman-ollama-prd
  #   ports:
  #     - "127.0.0.1:11435:11434"
  #   volumes:
  #     - ollama_data_prd:/root/.ollama
  #   networks:
  #     - wingman-network-prd
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 8G
  #   labels:
  #     - "com.wingman.compose-file=docker-compose.prd.yml"
  #     - "com.wingman.environment=production"
  #   healthcheck:
  #     # Note: ollama/ollama image does NOT include curl, use ollama CLI instead
  #     test: ["CMD", "ollama", "list"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"

networks:
  wingman-network-prd:
    driver: bridge
    name: wingman-network-prd

volumes:
  postgres_data_prd:
    driver: local
  redis_data_prd:
    driver: local
  # ollama_data_prd:  # Commented out - using host Ollama
  #   driver: local

